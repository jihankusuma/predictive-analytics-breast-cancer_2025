# -*- coding: utf-8 -*-
"""Predictive_Analytics_Breast_Cancer (3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Or4ld7t8hWLepXWevYHXwm7X4GnLs19m

#**Predictive Analytics [Breast Cancer](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset)**
- **Nama:** Jihan Kusumawardhani
- **Email:** jihankusumawwardhani@gmail.com
- **ID Dicoding:** https://www.dicoding.com/users/jihankusumawardhani
- **Modul:** Submission 1 Machine Learning Terapan
-**Dataset:** [Breast Cancer Dataset](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset)

# 1.Mengambil data dari kaggle
"""

!pip install -q kaggle

"""Kode ini digunakan untuk **menginstal *library* resmi dari Kaggle**.

* `!pip install`: Perintah untuk menginstal sebuah pustaka Python.
* `kaggle`: Nama pustaka yang diinstal, yang berfungsi sebagai antarmuka baris perintah (CLI) untuk berinteraksi dengan platform Kaggle.
* `-q`: Opsi untuk mode "quiet" (senyap), yang berarti proses instalasi tidak akan menampilkan banyak teks atau log, membuat output lebih bersih.

# 2. Mengimpor pustaka/modul python yang dibutuhkan
"""

#Import Load data Library
from google.colab import files\
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import zipfile
import numpy as np
from sklearn.preprocessing import OneHotEncoder
# Import train test split
from sklearn.model_selection import train_test_split
# Import Minmaxscaler
from sklearn.preprocessing import MinMaxScaler
# Import MinMaxScaler and StandardScaler
from sklearn.preprocessing import MinMaxScaler, StandardScaler
#Import Model
from sklearn.neighbors import KNeighborsClassifier # --> KNN
from sklearn.ensemble import RandomForestClassifier # --> RF
from sklearn.metrics import accuracy_score # --> matrix accuracy
from sklearn.svm import SVC # --> SVM
from sklearn.naive_bayes import BernoulliNB # --> Naive bayes
from sklearn.ensemble import ExtraTreesClassifier # --> Extra Trees Classifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from sklearn.svm import SVC
import xgboost as xgb
import lightgbm as lgb
from sklearn.linear_model import LogisticRegression

from sklearn.naive_bayes import GaussianNB

from google.colab import files
files.upload()
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d yasserh/breast-cancer-dataset

zip_ref = zipfile.ZipFile('/content/breast-cancer-dataset.zip', 'r')
zip_ref.extractall('/content/')
zip_ref.close()

"""Dari kode impor di atas, kita dapat melihat beberapa pustaka (library) dan modul yang dimuat, dikelompokkan berdasarkan fungsinya:

* Terdapat pustaka untuk **Pemuatan dan Manipulasi Data**, yaitu: `pandas` (untuk mengelola DataFrame), `files` dari `google.colab` (untuk mengunggah file di Colab), dan `zipfile` (untuk menangani file .zip).

* Terdapat pustaka untuk **Visualisasi Data**, yaitu: `matplotlib.pyplot` dan `seaborn` untuk membuat berbagai macam plot dan grafik.

* Terdapat modul untuk **Persiapan Data (Preprocessing)**, yaitu: `train_test_split` (untuk membagi data menjadi data latih dan data uji) dan `MinMaxScaler` (untuk mengubah skala nilai fitur).

* Terdapat berbagai **Model Machine Learning** untuk klasifikasi, yaitu: `KNeighborsClassifier` (KNN), `RandomForestClassifier` (RF), `SVC` (SVM), `BernoulliNB` dan `GaussianNB` (Naive Bayes), `ExtraTreesClassifier`, `xgboost`, `lightgbm`, dan `LogisticRegression`.

* Terdapat modul untuk **Evaluasi Model**, yaitu: `accuracy_score` untuk mengukur tingkat akurasi dari prediksi model.

# 3. Data Understanding

## 3.1 Memuat Data pada sebuah Dataframe menggunakan pandas
"""

df = pd.read_csv('/content/breast-cancer.csv')

"""## 3.2 Memuat Info/type kolom pada dataset"""

df

"""Dari dataframe di atas, kita dapat melihat bahwa dataset ini (dikenal sebagai Wisconsin Breast Cancer dataset) memiliki banyak kolom fitur. Berikut adalah penjelasan untuk 10 fitur utamanya:
* `id` : Parameter unik untuk identifikasi, tidak relevan untuk pemodelan dan akan dihilangkan dari dataset.
* `diagnosis` : Hasil diagnosis tumor, biasanya berupa kategori (misalnya 'M' untuk Ganas dan 'B' untuk Jinak).
* `radius_mean` : Rata-rata jari-jari dari inti sel tumor.
* `texture_mean` : Rata-rata tekstur, yang diukur dari standar deviasi nilai *grayscale* pada citra inti sel.
* `perimeter_mean` : Rata-rata keliling inti sel tumor.
* `area_mean` : Rata-rata luas inti sel tumor.
* `smoothness_mean` : Rata-rata kehalusan kontur inti sel.
* `compactness_mean` : Rata-rata tingkat kepadatan inti sel (dihitung dari `perimeter` dan `area`).
* `concavity_mean` : Rata-rata tingkat kecekungan pada kontur inti sel.
* `concave points_mean` : Rata-rata jumlah titik cekung pada kontur inti sel.
* `symmetry_mean` : Rata-rata simetri inti sel.
* `fractal_dimension_mean`: Rata-rata dimensi fraktal dari kontur inti sel.

Kolom-kolom lain dengan akhiran `_se` (standard error) dan `_worst` (nilai
terburuk atau terbesar) adalah pengukuran statistik turunan dari 10 fitur utama di atas.
"""

df.info()

"""Dari eksekusi method `df.info()` pada gambar tersebut, dapat disimpulkan, terdapat **32 kolom numerik**, yang terdiri dari:
    
* **30 kolom** dengan tipe data `float64` (contoh: `radius_mean`, `texture_mean`, `perimeter_mean`, `area_mean`, dan seterusnya).

* **1 kolom** dengan tipe data `int64`, yaitu `id`.

* Terdapat **1 kolom** dengan tipe data `object`, yaitu `diagnosis`.

Kolom `diagnosis` yang bertipe `object` ini merupakan kolom target atau label. Meskipun tipe datanya bukan angka, ini sudah sesuai karena kolom ini berisi kategori (misalnya 'M' untuk *Malignant* dan 'B' untuk *Benign*). Nantinya, kolom ini perlu diubah menjadi format numerik (misalnya 0 dan 1) agar dapat diproses oleh model machine learning.
"""

# Menghitung jumlah data kosong pada setiap kolom
df.isna().sum()

# Memuat ukuran shape pada data\frame
df.shape

"""Dari eksekusi method` df.shape` Terlihat:
<br>

| Jumlah Baris | Jumlah Kolom |
| ------ | ------ |
| 569 | 32 |


<br>
"""

#menghapus kolom yang tidak diperlukan
df.drop(['id'], axis=1, inplace=True)

df.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

## 3.3 Visualisasi Data
"""

# membagi dataset menjadi 2 bagian yaitu kategorial dan numerik
categorical_features = ['diagnosis']
numerical_features = [
                      'radius_mean',
                      'texture_mean',
                      'perimeter_mean',
                      'area_mean',
                      'smoothness_mean',
                      'compactness_mean',
                      'concavity_mean',
                      'concave points_mean',
                      'symmetry_mean',
                      'fractal_dimension_mean',
                      'radius_se',
                      'texture_se',
                      'perimeter_se',
                      'area_se',
                      'smoothness_se',
                      'compactness_se',
                      'concavity_se',
                      'concave points_se',
                      'symmetry_se',
                      'fractal_dimension_se',
                      'radius_worst',
                      'texture_worst',
                      'perimeter_worst',
                      'area_worst',
                      'smoothness_worst',
                      'compactness_worst',
                      'concavity_worst',
                      'concave points_worst',
                      'symmetry_worst',
                      'fractal_dimension_worst'
                      ]

"""### 3.3.1 Distribusi Kolom Kategorial"""

import pandas as pd
feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
data = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(data)
count.plot(kind='bar', title=feature, color='maroon');

"""* **Pemilihan dan Perhitungan Fitur:**
    * `feature = categorical_features[0]`: Memilih satu nama fitur dari sebuah list `categorical_features`. Berdasarkan outputnya, fitur yang terpilih adalah `diagnosis`.
    * `count = df[feature].value_counts()`: Menghitung jumlah sampel untuk setiap nilai unik dalam kolom `diagnosis`. (Contoh: 357 sampel untuk kelas 0, dan 212 untuk kelas 1).
    * `percent = 100*df[feature].value_counts(normalize=True)`: Menghitung persentase untuk setiap nilai unik.

* **Pembuatan DataFrame Ringkasan:**
    * `data = pd.DataFrame(...)`: Membuat sebuah DataFrame baru bernama `data` yang berisi ringkasan dari hasil perhitungan `jumlah sampel` dan `persentase`.
    * `print(data)`: Menampilkan DataFrame ringkasan tersebut, seperti yang terlihat pada output di bawah kode.

* **Visualisasi Data:**
    * `count.plot(kind='bar', ...)`: Membuat visualisasi dalam bentuk **diagram batang (bar chart)** dari data `count`.
    * Plot ini secara visual menunjukkan perbandingan jumlah sampel antara kelas 0 dan kelas 1 pada fitur `diagnosis`.

### 3.3.2 Distribusi Kolom Numerik
"""

df[numerical_features].hist(bins=50, figsize=(20,15), color='maroon')
plt.show()

"""### 3.3.3 Korelasi pada tiap kolom"""

df_numeric = df.select_dtypes(include=np.number)
correlation_matrix = df_numeric.corr().round(2)
plt.figure(figsize=(20, 10))
sns.heatmap(data=correlation_matrix, annot=True, cmap='Reds', linewidths=0.5) # Warna maroon mendekati merah
plt.title("Correlation Matrix untuk Fitur Numerik", size=20)
plt.show()

"""# 4. Persiapan Data (Data Preparation)

### 4.1 Melakukan eksplorasi pada kolom `diagnosis` (target) untuk mengidentifikasi nilai unik yang bertipe *object* sebagai persiapan untuk tahap transformasi data.
"""

print("Unique Values for Diagnosis", df['diagnosis'].unique())

oh = OneHotEncoder()

"""### 4.2 Langkah ini mencakup proses pengkodean ulang (mapping) pada kolom target diagnosis untuk mengubah format datanya dari tipe object menjadi representasi integer numerik, sebuah prasyarat fundamental agar data dapat diinterpretasikan secara efektif oleh model machine learning"""

diagnosis_mapping = {'B': 0, 'M': 1}
df['diagnosis'] = df['diagnosis'].map(diagnosis_mapping)

df

"""### 4.3 Melakukan perhitungan jumlah baris terhadap kolom target."""

df.diagnosis.value_counts()

"""### 4.4 Melakukan pembagian dataset:


*    train_test_split




"""

X = df.drop('diagnosis',axis=1)
y = df['diagnosis']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### 4.6 Melakukan Standard Scaler"""

sc=StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# 5. Pembuatan Model

### 5.1 Algoritma Random Forest
"""

RF = RandomForestClassifier()
RF.fit(X_train, y_train)

# Pengujian model terhadap data test
RF_pred = RF.predict(X_test)

accuracy_score(y_test, RF_pred)

RF_cr = classification_report(y_test, RF_pred, output_dict=True)
pd.DataFrame(RF_cr).transpose()

"""### 5.2 Algoritma K-Nearest Neighbor"""

KNN = KNeighborsClassifier()
KNN.fit(X_train, y_train)

# Pengujian model terhadap data test
KNN_pred = KNN.predict(X_test)

accuracy_score(y_test, KNN_pred)

KNN_cr = classification_report(y_test, KNN_pred, output_dict=True)
pd.DataFrame(KNN_cr).transpose()

"""### 5.3 Algoritma Support Vector Machine"""

SVM = SVC()
SVM.fit(X_train, y_train)

# Pengujian model terhadap data test
SVM_pred = SVM.predict(X_test)

accuracy_score(y_test, RF_pred)

SVM_cr = classification_report(y_test, SVM_pred, output_dict=True)
pd.DataFrame(SVM_cr).transpose()

"""### 5.4 Algoritma Gradient Boosting Machines

"""

from sklearn.ensemble import GradientBoostingClassifier
GBM = GradientBoostingClassifier()
GBM.fit(X_train, y_train)

GBM_pred = GBM.predict(X_test)

GBM_cr = classification_report(y_test, GBM_pred, output_dict=True)
pd.DataFrame(GBM_cr).transpose()

"""### 5.5 Algoritma Logistic Regression"""

LR = LogisticRegression()
LR.fit(X_train, y_train)

LR_pred = LR.predict(X_test)

LR_cr = classification_report(y_test, LR_pred, output_dict=True)
pd.DataFrame(LR_cr).transpose()

"""### 5.6 Algoritma Gaussian Naive Bayes"""

GNB = GaussianNB()
GNB.fit(X_train, y_train)

GNB_pred = GNB.predict(X_test)
accuracy_score(y_test, GNB_pred)

GNB_cr = classification_report(y_test, GNB_pred, output_dict=True)
pd.DataFrame(GNB_cr).transpose()

"""# 6. Evaluasi Model

### 6.1 Perbandingan metriks antara model
"""

RF_cr['accuracy']

all_metrics = {
    'accuracy': [
        RF_cr['accuracy'],
        KNN_cr['accuracy'],
        SVM_cr['accuracy'],
        GBM_cr['accuracy'],
        LR_cr['accuracy'],
        GNB_cr['accuracy']
    ],
    'f1-score_0': [
        RF_cr['0']['f1-score'],
        KNN_cr['0']['f1-score'],
        SVM_cr['0']['f1-score'],
        GBM_cr['0']['f1-score'],
        LR_cr['0']['f1-score'],
        GNB_cr['0']['f1-score']
    ],
    'precision_0': [
        RF_cr['0']['precision'],
        KNN_cr['0']['precision'],
        SVM_cr['0']['precision'],
        GBM_cr['0']['precision'],
        LR_cr['0']['precision'],
        GNB_cr['0']['precision']
    ],
    'recall_0': [
        RF_cr['0']['recall'],
        KNN_cr['0']['recall'],
        SVM_cr['0']['recall'],
        GBM_cr['0']['recall'],
        LR_cr['0']['recall'],
        GNB_cr['0']['recall']
    ],
    'f1-score_1': [
        RF_cr['1']['f1-score'],
        KNN_cr['1']['f1-score'],
        SVM_cr['1']['f1-score'],
        GBM_cr['1']['f1-score'],
        LR_cr['1']['f1-score'],
        GNB_cr['1']['f1-score']
    ],
    'precision_1': [
        RF_cr['1']['precision'],
        KNN_cr['1']['precision'],
        SVM_cr['1']['precision'],
        GBM_cr['1']['precision'],
        LR_cr['1']['precision'],
        GNB_cr['1']['precision']
    ],
    'recall_1': [
        RF_cr['1']['recall'],
        KNN_cr['1']['recall'],
        SVM_cr['1']['recall'],
        GBM_cr['1']['recall'],
        LR_cr['1']['recall'],
        GNB_cr['1']['recall']
    ]
}


all_model_names = [
    'RF',
    'KNN',
    'SVM',
    'GBM',
    'LogisticRegression',
    'Gaussian Naive Bayes'
]


metrics = pd.DataFrame(all_metrics, index=all_model_names)

# Definisikan struktur MultiIndex untuk header kolom
multiheader = [
    ('', 'accuracy'),
    ('Class 0', 'f1-score'),
    ('Class 0', 'precision'),
    ('Class 0', 'recall'),
    ('Class 1', 'f1-score'),
    ('Class 1', 'precision'),
    ('Class 1', 'recall')
]
metrics.columns = pd.MultiIndex.from_tuples(multiheader)

# Menampilkan dataframe perbandingan akhir
metrics

"""# 6.2 Confussion Matrix

### 6.2.1 Visualisasi Algoritma Random Forest
"""

RF_cm = confusion_matrix(y_test,RF_pred)
sns.heatmap(RF_cm,annot=True,fmt="d", cmap='Reds')

"""### 6.2.2 Visualisasi Algoritma K-Nearest Neighbor"""

KNN_cm = confusion_matrix(y_test,KNN_pred)
sns.heatmap(KNN_cm,annot=True,fmt="d", cmap='Reds')

"""### 6.2.2 Visualisasi Algoritma Support Vector Machine"""

SVM_cm = confusion_matrix(y_test,SVM_pred)
sns.heatmap(SVM_cm,annot=True,fmt="d", cmap='Reds')

"""### 6.2.2 Visualisasi Algoritma Gradient Boosting Machines"""

GBM_cm = confusion_matrix(y_test,GBM_pred)
sns.heatmap(GBM_cm,annot=True,fmt="d",cmap='Reds' )

"""### 6.2.2 Visualisasi Algoritma Logistic Regression"""

LR_cm = confusion_matrix(y_test,LR_pred)
sns.heatmap(LR_cm,annot=True,fmt="d", cmap='Reds')

"""### 6.2.2 Visualisasi Algoritma Gaussian Naive Bayes"""

GNB_cm = confusion_matrix(y_test,GNB_pred)
sns.heatmap(GNB_cm,annot=True,fmt="d", cmap='Reds')